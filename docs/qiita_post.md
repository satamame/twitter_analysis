# トピックモデルによる Twitter の分類

Python の gensim というライブラリを使って、Twitter のツイートの分類にチャレンジしました。
その過程で得た知見などをご報告します。

# 動機

#### 短文の分類をしたかった

もともと個人的なプロジェクトとして、演劇の台本を自動的に構造化する仕組みを作りたいと思っていました。
それで、台本の各行を「セリフ行」や「ト書き行」に分類する方法を模索していました。

#### 教師なし学習をしたかった

短文を分類するタスクを試すのに、Twitter のデータを使えると思いました。
教師ラベルがないことで、どんな分類ができるのか (或は本当はできないのか) 興味がありました。

#### 自分でデータセットを作りたかった

学習用に公開されているデータセットを使うのでなく、自分でデータを収集して、それでモデルが出来るのを見てみたいと思いました。

#### 余力があれば…

余力があれば、ユーザごとのトピックの分布にパターンがあるか調べてみたいと思いましたが、今回はやっていません。
ユーザごとのパターンとは例えば、「主にこのトピックを投稿する人は、あのトピックも投稿する傾向がある」とか、そういうのです。

# 準備

#### Twitter App

Twitter の API を使えるように、アプリケーションを登録しておきます。
(参考) [PHP+OAuthでTwitter](https://sdn-project.net/labo/oauth.html)

#### Python のライブラリ

以下のライブラリをインストールしました。
使ったバージョンについては、[リポジトリ](https://github.com/satamame/twitter_analysis)の Pipfile.lock を御覧ください。

- **Tweepy**
    - Twitter API にアクセスするために使います。
- **PyMongo**
    - MongoDB にアクセスするために使います。
- **Janome**
    - 形態素解析に使います。
- **gensim**
    - トピックモデルを簡単に生成できます。

#### 実行環境

- **VSCode**
    - Python 拡張を入れることで、.py ファイルをインタラクティブに実行できます。
    - Windows で作業したので、Explorer から VSCode でフォルダを開けるようにしました。  
    (参考) [フォルダ右クリックで VSCode で開く](
    https://satamame.hatenablog.com/entry/2019/05/12/182037)
    - さらに、フォルダを開いたら自動的に .venv フォルダを見に行くようにしました (設定で "python.venvPath" の値を ".venv" とします)。

#### DB

- **MongoDB**
    - 取得したツイートを JSON 形式のまま保存して検索したかったので、MongoDB を使いました。
    - インストーラの指示に従って、サービス化までしておきます。
    - 使ったバージョンは `4.0.9` です。