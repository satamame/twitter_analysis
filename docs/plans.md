# Plans

## やってみたいこと

- トピックモデルの作成
- トピックモデルを使った、ツイッターユーザの分類

## 計画と結果
---
### 事前準備

プロジェクト開始前に、以下の準備をしました。
- Twitter API へのアクセス
- Tweepy の使い方の確認
- MongoDB のインストール
- PyMongo の使い方の確認
- NoSQLBooster for MongoDB のインストール
- 検索したツイートを MongoDB に保存する実験
- 保存したツイートのユーザ情報だけを抜き出す実験

---
### 05-18 (土)

予定
- どれくらいのツイートを取得できるか実験する。

結果
- 一度に1,200程度のツイートを取得できるようです。

---
### 05-19 (日)

予定
- サンプルツイートを10,000件、DB に保存する。
- サンプルツイートからユーザ情報を抜き出して DB に保存する。
- 今までにやった事などを、一旦ドキュメントにまとめる。
- ラップトップにも開発環境を整える。

結果
- 11,231件のツイートを DB に保存しました。
- 10,793件のユーザ情報を DB に保存しました。

---
### 05-20 (月)

予定
- retrieve_usr_tweets.py を、中断・再開できるようにする。

結果
- retrieve_usr_tweets.py で、ユーザにサンプルとして選ばれたというフラグと、取得したツイート数を記録するようにしました。
- これにより、スクリプトが中断しても、追加でユーザごとのツイートを取得できます。

---
### 05-21 (火)

予定
- gensim の勉強を開始。

結果
- ラップトップに DB のデータを移行することが出来ませんでした（要調査）。
- Janome, scikit-learn, gensim をインストールしました。
- gensim の勉強はできませんでした。

---
### 05-22 (水)

予定
- なし

結果
- DB に保存したツイートを Janome で形態素解析することは可能になりました。
- 名詞, 動詞, 形容詞, 形容動詞の基本形を取るようにしたが、特徴として良くないものも拾ってしまっているので、何とかしたいです。
- 単語列にしたら、一旦 DB に戻すようにする予定。

---
### 05-23 (木)

予定
- Twitter API からのエラーを正しく処理する。

結果
- Rate limit error なら15分待ち、それ以外なら処理を中断するようにしました。
